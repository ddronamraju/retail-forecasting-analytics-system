{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d501890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# Add feature_engineering module to path\n",
    "sys.path.append(\"../feature_engineering\")\n",
    "from feature_utils import make_features\n",
    "\n",
    "# Create images directory\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec872e0",
   "metadata": {},
   "source": [
    "## 1. Load Data for Multiple Store‚ÄìDept Combinations\n",
    "\n",
    "Instead of filtering to a single Store‚ÄìDept, we'll load **multiple combinations** to train a global model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20367f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full training data\n",
    "df = pd.read_csv(\"../baseline_prophet_forecast/data/train.csv\", parse_dates=[\"Date\"])\n",
    "\n",
    "# Select a representative sample of Store-Dept combinations\n",
    "# For demo, use Store 1 with multiple departments + Store 2 with some departments\n",
    "selected_combos = [\n",
    "    (1, 1), (1, 2), (1, 3), (1, 4), (1, 5),  # Store 1, multiple depts\n",
    "    (2, 1), (2, 2), (2, 3),                   # Store 2, multiple depts\n",
    "    (3, 1), (3, 2),                           # Store 3, few depts (simulate limited history)\n",
    "]\n",
    "\n",
    "# Filter to selected combinations\n",
    "df_filtered = df[\n",
    "    df.apply(lambda x: (x['Store'], x['Dept']) in selected_combos, axis=1)\n",
    "].copy()\n",
    "\n",
    "print(f\"Total records: {len(df_filtered):,}\")\n",
    "print(f\"\\nStore-Dept combinations: {df_filtered.groupby(['Store', 'Dept']).size().shape[0]}\")\n",
    "print(f\"\\nRecords per combination:\")\n",
    "print(df_filtered.groupby(['Store', 'Dept']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eb67ae",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering with Entity IDs\n",
    "\n",
    "Global models require:\n",
    "1. **Time-series features** (lags, rolling stats) computed per entity\n",
    "2. **Entity identifiers** (Store, Dept) as categorical features for cross-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e40d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_global_features(df):\n",
    "    \"\"\"\n",
    "    Create features for global model across multiple Store-Dept combinations.\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    \n",
    "    for (store, dept), group in df.groupby(['Store', 'Dept']):\n",
    "        # Sort by date and set as index\n",
    "        entity_df = group.sort_values('Date').set_index('Date')\n",
    "        \n",
    "        # Create time-series features using reusable function\n",
    "        entity_features = make_features(entity_df, target='Weekly_Sales')\n",
    "        \n",
    "        # Add entity identifiers\n",
    "        entity_features['Store'] = store\n",
    "        entity_features['Dept'] = dept\n",
    "        \n",
    "        # Add target variable\n",
    "        entity_features['Weekly_Sales'] = entity_df['Weekly_Sales']\n",
    "        \n",
    "        all_features.append(entity_features)\n",
    "    \n",
    "    # Concatenate all entities\n",
    "    global_df = pd.concat(all_features, axis=0)\n",
    "    return global_df\n",
    "\n",
    "# Generate global features\n",
    "features_df = make_global_features(df_filtered)\n",
    "\n",
    "print(f\"Global feature dataset shape: {features_df.shape}\")\n",
    "print(f\"\\nFeature columns: {features_df.columns.tolist()[:10]}...\")\n",
    "print(f\"\\nSample data:\")\n",
    "print(features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffae0661",
   "metadata": {},
   "source": [
    "## 3. Train-Test Split\n",
    "\n",
    "For time-series forecasting:\n",
    "- **Training**: Earlier time periods (e.g., first 80% of data per entity)\n",
    "- **Testing**: Recent time periods (last 20%) to simulate forward-looking forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e24dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cutoff date for train/test split (80/20 split)\n",
    "# Calculate per-entity cutoff to ensure balanced split\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for (store, dept), group in features_df.groupby(['Store', 'Dept']):\n",
    "    group_sorted = group.sort_index()\n",
    "    n = len(group_sorted)\n",
    "    cutoff_idx = int(n * 0.8)\n",
    "    \n",
    "    train_list.append(group_sorted.iloc[:cutoff_idx])\n",
    "    test_list.append(group_sorted.iloc[cutoff_idx:])\n",
    "\n",
    "train_df = pd.concat(train_list)\n",
    "test_df = pd.concat(test_list)\n",
    "\n",
    "print(f\"Training samples: {len(train_df):,}\")\n",
    "print(f\"Testing samples: {len(test_df):,}\")\n",
    "print(f\"\\nDate range - Train: {train_df.index.min()} to {train_df.index.max()}\")\n",
    "print(f\"Date range - Test: {test_df.index.min()} to {test_df.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80631b88",
   "metadata": {},
   "source": [
    "## 4. Prepare Features and Target\n",
    "\n",
    "Remove any rows with NaN values (from lagging/rolling window startup) and separate features from target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6966a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values created by lagging/rolling features\n",
    "train_clean = train_df.dropna()\n",
    "test_clean = test_df.dropna()\n",
    "\n",
    "# Separate features and target\n",
    "target_col = 'Weekly_Sales'\n",
    "feature_cols = [col for col in train_clean.columns if col != target_col]\n",
    "\n",
    "X_train = train_clean[feature_cols]\n",
    "y_train = train_clean[target_col]\n",
    "\n",
    "X_test = test_clean[feature_cols]\n",
    "y_test = test_clean[target_col]\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples, {X_train.shape[1]} features\")\n",
    "print(f\"Testing set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nFeature dtypes:\")\n",
    "print(X_train.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77614f0e",
   "metadata": {},
   "source": [
    "## 5. Train Global LightGBM Model\n",
    "\n",
    "Key hyperparameters for global models:\n",
    "- **Categorical features**: Store and Dept encoded as categories for efficient tree splits\n",
    "- **More trees**: Global models benefit from higher `n_estimators` due to diverse patterns\n",
    "- **Regularization**: Higher `reg_alpha`/`reg_lambda` to prevent overfitting to dominant entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c642db70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Store and Dept to categorical for LightGBM\n",
    "categorical_features = ['Store', 'Dept']\n",
    "for col in categorical_features:\n",
    "    X_train[col] = X_train[col].astype('category')\n",
    "    X_test[col] = X_test[col].astype('category')\n",
    "\n",
    "# Train global LightGBM model\n",
    "model = LGBMRegressor(\n",
    "    n_estimators=800,           # More trees for global model\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    num_leaves=31,\n",
    "    min_child_samples=20,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,              # L1 regularization\n",
    "    reg_lambda=0.1,             # L2 regularization\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "print(\"Training global LightGBM model...\")\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    categorical_feature=categorical_features\n",
    ")\n",
    "\n",
    "print(\"‚úì Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682b584d",
   "metadata": {},
   "source": [
    "## 6. Evaluate Global Model Performance\n",
    "\n",
    "Evaluate both:\n",
    "- **Overall metrics**: Aggregated across all Store-Dept combinations\n",
    "- **Per-entity metrics**: Performance breakdown by Store-Dept to identify weak performers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd7e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Overall metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"GLOBAL MODEL PERFORMANCE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MAE:  ${mae:,.2f}\")\n",
    "print(f\"RMSE: ${rmse:,.2f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb094b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-entity performance analysis\n",
    "results_df = X_test.copy()\n",
    "results_df['Actual'] = y_test.values\n",
    "results_df['Predicted'] = y_pred\n",
    "results_df['Error'] = results_df['Actual'] - results_df['Predicted']\n",
    "results_df['Abs_Error'] = np.abs(results_df['Error'])\n",
    "\n",
    "# Calculate per-entity metrics\n",
    "entity_metrics = results_df.groupby(['Store', 'Dept']).agg({\n",
    "    'Abs_Error': 'mean',\n",
    "    'Actual': 'count'\n",
    "}).rename(columns={'Abs_Error': 'MAE', 'Actual': 'Test_Samples'}).round(2)\n",
    "\n",
    "entity_metrics = entity_metrics.sort_values('MAE', ascending=False)\n",
    "\n",
    "print(\"\\nPer-Entity Performance (Top 10 by MAE):\")\n",
    "print(entity_metrics.head(10))\n",
    "\n",
    "print(\"\\nPer-Entity Performance (Bottom 10 by MAE):\")\n",
    "print(entity_metrics.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3c22f5",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis\n",
    "\n",
    "Understanding which features drive predictions in a global model:\n",
    "- **Entity features** (Store, Dept): High importance indicates entity-specific patterns\n",
    "- **Time-series features** (lags, rolling stats): High importance indicates temporal patterns\n",
    "- **Calendar features** (month, weekofyear): High importance indicates seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6858cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot top 20 features\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=importance_df.head(20), y='Feature', x='Importance', palette='viridis')\n",
    "plt.title('Top 20 Feature Importances (Global Model)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/global_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 15 Features:\")\n",
    "print(importance_df.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca52b4e",
   "metadata": {},
   "source": [
    "## 8. Visualize Predictions for Selected Entities\n",
    "\n",
    "Compare actual vs predicted for a few Store-Dept combinations to assess model quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9f50e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 3 entities for visualization\n",
    "viz_entities = [(1, 1), (2, 1), (3, 1)]\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "for idx, (store, dept) in enumerate(viz_entities):\n",
    "    # Filter results for this entity\n",
    "    entity_results = results_df[\n",
    "        (results_df['Store'] == store) & (results_df['Dept'] == dept)\n",
    "    ].sort_index()\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[idx]\n",
    "    ax.plot(entity_results.index, entity_results['Actual'], \n",
    "            label='Actual', linewidth=2, marker='o', markersize=4)\n",
    "    ax.plot(entity_results.index, entity_results['Predicted'], \n",
    "            label='Predicted', linewidth=2, marker='s', markersize=4, alpha=0.7)\n",
    "    ax.fill_between(entity_results.index, \n",
    "                     entity_results['Actual'], \n",
    "                     entity_results['Predicted'],\n",
    "                     alpha=0.2, color='red')\n",
    "    \n",
    "    entity_mae = entity_metrics.loc[(store, dept), 'MAE']\n",
    "    ax.set_title(f'Store {store}, Dept {dept} | MAE: ${entity_mae:,.2f}', \n",
    "                fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Weekly Sales ($)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes[-1].set_xlabel('Date')\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/global_model_predictions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3bc75d",
   "metadata": {},
   "source": [
    "## 9. Cold-Start Scenario Simulation\n",
    "\n",
    "**Key advantage of global models**: Can predict for new entities with **zero historical data** by leveraging patterns from similar entities.\n",
    "\n",
    "### Simulation:\n",
    "1. Pretend Store 3, Dept 2 is a **brand new entity** with no training data\n",
    "2. Remove it from training set\n",
    "3. Train a new global model\n",
    "4. Predict for Store 3, Dept 2 using only entity ID features\n",
    "5. Compare to actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7a414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cold-start entity\n",
    "cold_start_entity = (3, 2)\n",
    "\n",
    "# Remove cold-start entity from training data\n",
    "train_no_coldstart = train_clean[\n",
    "    ~((train_clean['Store'] == cold_start_entity[0]) & \n",
    "      (train_clean['Dept'] == cold_start_entity[1]))\n",
    "]\n",
    "\n",
    "# Get cold-start entity test data\n",
    "cold_start_test = test_clean[\n",
    "    (test_clean['Store'] == cold_start_entity[0]) & \n",
    "    (test_clean['Dept'] == cold_start_entity[1])\n",
    "]\n",
    "\n",
    "print(f\"Cold-start entity: Store {cold_start_entity[0]}, Dept {cold_start_entity[1]}\")\n",
    "print(f\"Training samples (excluding cold-start): {len(train_no_coldstart):,}\")\n",
    "print(f\"Cold-start test samples: {len(cold_start_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a5545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model without cold-start entity\n",
    "X_train_no_cold = train_no_coldstart[feature_cols]\n",
    "y_train_no_cold = train_no_coldstart[target_col]\n",
    "\n",
    "# Convert categorical features\n",
    "for col in categorical_features:\n",
    "    X_train_no_cold[col] = X_train_no_cold[col].astype('category')\n",
    "\n",
    "model_no_cold = LGBMRegressor(\n",
    "    n_estimators=800,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "print(\"Training model WITHOUT cold-start entity...\")\n",
    "model_no_cold.fit(\n",
    "    X_train_no_cold, \n",
    "    y_train_no_cold,\n",
    "    categorical_feature=categorical_features\n",
    ")\n",
    "print(\"‚úì Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599d3a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for cold-start entity\n",
    "X_cold_start = cold_start_test[feature_cols]\n",
    "y_cold_start = cold_start_test[target_col]\n",
    "\n",
    "# Convert categorical features\n",
    "for col in categorical_features:\n",
    "    X_cold_start[col] = X_cold_start[col].astype('category')\n",
    "\n",
    "y_cold_pred = model_no_cold.predict(X_cold_start)\n",
    "\n",
    "# Evaluate cold-start performance\n",
    "cold_mae = mean_absolute_error(y_cold_start, y_cold_pred)\n",
    "cold_rmse = np.sqrt(mean_squared_error(y_cold_start, y_cold_pred))\n",
    "cold_mape = np.mean(np.abs((y_cold_start - y_cold_pred) / y_cold_start)) * 100\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"COLD-START PERFORMANCE (Store {cold_start_entity[0]}, Dept {cold_start_entity[1]})\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MAE:  ${cold_mae:,.2f}\")\n",
    "print(f\"RMSE: ${cold_rmse:,.2f}\")\n",
    "print(f\"MAPE: {cold_mape:.2f}%\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\n‚úì Model successfully predicted for an entity with ZERO training history!\")\n",
    "print(\"  This demonstrates the power of global models for handling new stores/products.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f26b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cold-start predictions\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(cold_start_test.index, y_cold_start, \n",
    "         label='Actual (New Entity)', linewidth=2, marker='o', markersize=6)\n",
    "plt.plot(cold_start_test.index, y_cold_pred, \n",
    "         label='Predicted (Global Model)', linewidth=2, marker='s', markersize=6, alpha=0.7)\n",
    "plt.fill_between(cold_start_test.index, y_cold_start, y_cold_pred,\n",
    "                alpha=0.2, color='orange')\n",
    "plt.title(f'Cold-Start Prediction: Store {cold_start_entity[0]}, Dept {cold_start_entity[1]} (Zero Training History)\\nMAE: ${cold_mae:,.2f}',\n",
    "         fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Weekly Sales ($)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/cold_start_prediction.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566bbd29",
   "metadata": {},
   "source": [
    "## 10. Save Global Model\n",
    "\n",
    "Save the trained global model for production deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c52f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the full global model (trained on all entities)\n",
    "model_path = \"../../artifacts/global_lgbm_model.pkl\"\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"‚úì Global model saved to: {model_path}\")\n",
    "\n",
    "# Save feature list for inference pipeline\n",
    "feature_list_path = \"../../artifacts/global_model_features.txt\"\n",
    "with open(feature_list_path, 'w') as f:\n",
    "    f.write('\\n'.join(feature_cols))\n",
    "print(f\"‚úì Feature list saved to: {feature_list_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ffbdca",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### ‚úÖ Advantages of Global Models\n",
    "1. **Cross-learning**: Model learns from patterns across all entities (e.g., holiday spikes are similar across stores)\n",
    "2. **Cold-start handling**: Can predict for new entities with zero historical data\n",
    "3. **Scalability**: One model serves thousands of entities vs. managing thousands of models\n",
    "4. **Consistency**: Same methodology applied across all forecasts\n",
    "5. **Maintenance**: Single model to retrain, monitor, and debug\n",
    "\n",
    "### ‚ö†Ô∏è Considerations\n",
    "1. **Entity diversity**: Works best when entities share similar patterns (e.g., all grocery stores)\n",
    "2. **Feature engineering**: Requires careful treatment of entity-specific features\n",
    "3. **Imbalanced entities**: Dominant entities (high volume stores) can overshadow smaller ones\n",
    "4. **Model complexity**: Needs more hyperparameter tuning than per-entity models\n",
    "\n",
    "### üöÄ Production Extensions\n",
    "- **Hierarchical features**: Add Store Type, Region, Department Category\n",
    "- **Entity embeddings**: Learn dense representations of Store/Dept IDs\n",
    "- **Hybrid approach**: Global model for most entities + specialized models for critical SKUs\n",
    "- **Online learning**: Incrementally update model as new data arrives\n",
    "- **Multi-horizon forecasting**: Predict 1-week, 4-week, 13-week ahead simultaneously"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
